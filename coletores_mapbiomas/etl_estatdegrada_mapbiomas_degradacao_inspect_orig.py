import os
import requests
import zipfile
import io
import json
import pandas as pd
import time
from tqdm import tqdm
from datetime import datetime

# ------------------------------------------------------------
# üõ†Ô∏è Vari√°veis principais de controle do script
# ------------------------------------------------------------

# üîó Caminho do arquivo JSON que cont√©m a lista de perfis dispon√≠veis.
# Este arquivo deve seguir a estrutura:
# {
#   "PERFIL_ATIVO": "<nome_do_perfil>",
#   "<nome_do_perfil>": {
#       "config": {...},
#       "interpreta_ano": "...",
#       "dicionario": {...}
#   }
# }
# O script utiliza o campo "PERFIL_ATIVO" para selecionar automaticamente
# qual perfil ser√° usado em cada execu√ß√£o.
ARQUIVO_PERFIS = "perfis_xlsx.json"

# üîÑ Controle da atualiza√ß√£o autom√°tica do arquivo de perfis (JSON).
# Se = True:
#   - Um backup ser√° gerado como "perfis_xlsx_bkp.json"
#   - O conte√∫do do bloco "dicionario" do perfil ativo ser√°
#     substitu√≠do pelos campos reais da planilha (mapeados e n√£o mapeados).
#     Campos ausentes no XLSX ser√£o removidos do dicion√°rio.
#     Campos encontrados, mas sem defini√ß√£o, ser√£o marcados com "‚ùì Definir significado".
#
# Se = False:
#   - Nenhum arquivo ser√° alterado.
#   - Apenas ser√° exibido no terminal um comparativo entre:
#       a) Os campos atuais do "dicionario" no JSON
#       b) Os campos detectados na planilha vinculada ao perfil ativo.
atualizar_json = True  # üîÅ Altere para False se quiser rodar apenas em modo leitura

# ------------------------------------------------------------
# üîß Carregar perfil ativo e seus dados do JSON
# ------------------------------------------------------------

def carregar_perfil(json_path):
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            perfis = json.load(f)
        perfil_ativo = perfis.get("PERFIL_ATIVO")
        dados_perfil = perfis.get(perfil_ativo, {})
        config = dados_perfil.get("config", {})
        dicionario = dados_perfil.get("dicionario", {})
        interpreta_ano = dados_perfil.get("interpreta_ano", "Ano {ano} (sem descri√ß√£o definida)")
        return perfil_ativo, perfis, config, dicionario, interpreta_ano
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao carregar JSON de perfis: {e}")
        return None, {}, {}, {}, "Ano {ano} (sem descri√ß√£o definida)"

PERFIL_ATIVO, TODOS_PERFIS, CONFIG, MAPEAMENTO_CAMPOS, INTERPRETA_ANO = carregar_perfil(ARQUIVO_PERFIS)
URL_ZIP = CONFIG.get("url_zip")
PASTA_DADOS = CONFIG.get("pasta_dados")
ARQUIVO_ALVO = CONFIG.get("arquivo_alvo")

# ------------------------------------------------------------
# üßº Limpar pasta de extra√ß√£o antes da execu√ß√£o
# ------------------------------------------------------------

def limpar_pasta_inicio(pasta):
    print("\nüßº Verificando pasta de dados...")
    os.makedirs(pasta, exist_ok=True)
    arquivos = os.listdir(pasta)

    if not arquivos:
        print("‚úÖ Pasta j√° est√° limpa.")
        return

    print(f"‚ö†Ô∏è Removendo {len(arquivos)} arquivos existentes...")
    for arquivo in tqdm(arquivos, desc="üßπ Limpando pasta", ncols=80):
        try:
            os.remove(os.path.join(pasta, arquivo))
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao remover {arquivo}: {e}")
    print("‚úÖ Pasta limpa com sucesso.")

# ------------------------------------------------------------
# üì• Download e extra√ß√£o do ZIP com barra de progresso
# ------------------------------------------------------------

def baixar_e_extrair_zip(url, destino):
    print("\nüì• Baixando ZIP...")
    res = requests.get(url, stream=True)
    total = int(res.headers.get('content-length', 0))
    buffer = io.BytesIO()
    progresso = tqdm(total=total, unit='B', unit_scale=True, desc='üì¶ Download', ncols=80)

    for chunk in res.iter_content(1024 * 64):
        buffer.write(chunk)
        progresso.update(len(chunk))
    progresso.close()

    print("üß© Extraindo conte√∫do do ZIP...")
    with zipfile.ZipFile(buffer) as z:
        z.extractall(destino)
    print("‚úÖ Arquivos extra√≠dos.")

# ------------------------------------------------------------
# üìò Inspecionar planilha e listar campos encontrados
# ------------------------------------------------------------

def inspecionar_planilha(caminho_arquivo):
    print(f"\nüìÑ Inspecionando planilha vinculada ao perfil: `{PERFIL_ATIVO}`")

    if not os.path.exists(caminho_arquivo):
        raise FileNotFoundError(f"‚ùå Planilha n√£o encontrada: {caminho_arquivo}")

    xls = pd.ExcelFile(caminho_arquivo, engine="openpyxl")
    aba = xls.sheet_names[0]
    df = pd.read_excel(xls, sheet_name=aba, nrows=5, engine="openpyxl")
    xls.close()

    colunas = [
        str(col).strip().lower().replace(" ", "_") if isinstance(col, str) else str(col)
        for col in df.columns
    ]

    print(f"üßæ Planilha: {os.path.basename(caminho_arquivo)} | Aba: {aba}")
    print("üìë Campos detectados:\n")

    for col in colunas:
        if col.isdigit() and 1980 <= int(col) <= 2100:
            print(f"üîπ {col}: {INTERPRETA_ANO.replace('{ano}', col)}")
        elif col in MAPEAMENTO_CAMPOS:
            print(f"üîπ {col}: {MAPEAMENTO_CAMPOS[col]}")
        else:
            print(f"üîπ {col}: ‚ùì Definir significado")

    return colunas

# ------------------------------------------------------------
# üîÑ Atualizar dicion√°rio do perfil ativo com os campos reais
# ------------------------------------------------------------

def atualizar_dicionario_json(colunas):
    print("\nüìÅ Atualizando dicion√°rio do perfil ativo...")

    try:
        with open(ARQUIVO_PERFIS, "r", encoding="utf-8") as f:
            original = json.load(f)

        # üïí Gerar timestamp no formato aammddhhmmss
        timestamp = datetime.now().strftime("%y%m%d%H%M%S")

        # üîç Obter PA_ID do perfil ativo
        pa_id = original.get(PERFIL_ATIVO, {}).get("PA_ID", "000")

        # üìÑ Nome do arquivo de backup com timestamp e PA_ID
        nome_backup = f"perfis_xlsx_bkp_{timestamp}_{pa_id}.json"

        # üß∑ Criar backup din√¢mico
        with open(nome_backup, "w", encoding="utf-8") as bkp:
            json.dump(original, bkp, indent=2, ensure_ascii=False)
        print(f"üß∑ Backup salvo como: {nome_backup}")

        novo_dicionario = {}
        for col in colunas:
            if col.isdigit() and 1980 <= int(col) <= 2100:
                continue
            desc = MAPEAMENTO_CAMPOS.get(col)
            novo_dicionario[col] = desc if desc else "‚ùì Definir significado"

        original[PERFIL_ATIVO]["dicionario"] = novo_dicionario

        with open(ARQUIVO_PERFIS, "w", encoding="utf-8") as f_final:
            json.dump(original, f_final, indent=2, ensure_ascii=False)
        print("‚úÖ JSON atualizado com os campos reais da planilha.")

    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao atualizar o JSON: {e}")

# ------------------------------------------------------------
# üëÄ Comparar campos JSON vs campos da planilha (modo leitura)
# ------------------------------------------------------------

def comparar_dicionario(colunas):
    json_campos = set(MAPEAMENTO_CAMPOS.keys())
    campos_planilha = set(c for c in colunas if not (c.isdigit() and 1980 <= int(c) <= 2100))

    extras_json = sorted(json_campos - campos_planilha)
    extras_planilha = sorted(campos_planilha - json_campos)

    print("\nüìä Comparativo entre JSON e planilha:")
    if extras_json:
        print("\nüî∫ Presentes no JSON, mas ausentes na planilha:")
        for c in extras_json:
            print(f"   ‚ö†Ô∏è {c}")

    if extras_planilha:
        print("\nüîπ Presentes na planilha, mas ausentes no JSON:")
        for c in extras_planilha:
            print(f"   ‚ùì {c}")

    if not extras_json and not extras_planilha:
        print("‚úÖ JSON est√° totalmente sincronizado com a planilha.")

# ------------------------------------------------------------
# üßπ Remover arquivos extra√≠dos ap√≥s uso
# ------------------------------------------------------------

def limpar_arquivos_finais(pasta):
    arquivos = os.listdir(pasta)
    for arquivo in tqdm(arquivos, desc="üßº Limpando arquivos finais", ncols=80):
        try:
            os.remove(os.path.join(pasta, arquivo))
        except Exception as e:
            print(f"‚ö†Ô∏è Falha ao remover {arquivo}: {e}")
    print("‚úÖ Finalizado.")

# ------------------------------------------------------------
# üöÄ Execu√ß√£o principal
# ------------------------------------------------------------

if __name__ == "__main__":
    if not PERFIL_ATIVO or not URL_ZIP or not PASTA_DADOS or not ARQUIVO_ALVO:
        print("‚ùå Perfil ativo ou configura√ß√µes incompletas no JSON.")
    else:
        inicio = time.time()

        limpar_pasta_inicio(PASTA_DADOS)
        baixar_e_extrair_zip(URL_ZIP, PASTA_DADOS)
        caminho_planilha = os.path.join(PASTA_DADOS, ARQUIVO_ALVO)
        colunas_planilha = inspecionar_planilha(caminho_planilha)

        if atualizar_json:
            atualizar_dicionario_json(colunas_planilha)
        else:
            comparar_dicionario(colunas_planilha)

        limpar_arquivos_finais(PASTA_DADOS)
        print(f"\n‚úÖ Script finalizado em {round(time.time() - inicio, 2)} segundos.")
